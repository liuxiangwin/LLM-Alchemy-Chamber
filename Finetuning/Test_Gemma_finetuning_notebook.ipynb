{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e229477a-a727-44e7-948f-77eec49cea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33m  WARNING: Did not find branch or tag '4c611f4', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git@main bitsandbytes --quiet # we need latest transformers for this\n",
    "!pip install git+https://github.com/huggingface/peft.git@4c611f4 --quiet\n",
    "!pip install datasets==2.19.1 --quiet\n",
    "!pip install accelerate -U --quiet\n",
    "!pip install wandb --quiet\n",
    "!pip install scipy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5fe091-6e0c-47ae-bfa8-4bfe246208d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /opt/app-root/src/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\n",
    "  token=\"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\", # ADD YOUR TOKEN HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6bf4c9-a4dd-464c-a1f5-0b02b0787da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaef59821814af1bee6ca3206946806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import pipeline \n",
    "\n",
    "\n",
    "# CommitInfo(commit_url='https://huggingface.co/Liu-Xiang/gemma-Code-Instruct-Finetune-test/commit/bfcbef99ca87a411a63fe5007dde38a71e6cf518', commit_message='Upload tokenizer', commit_description='', oid='bfcbef99ca87a411a63fe5007dde38a71e6cf518', pr_url=None, pr_revision=None, pr_num=None)\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    # \"Liu-Xiang/gemma-Code-Instruct-Finetune-test\",\n",
    "    # \"google/gemma-2b\",\n",
    "    \"Liu-Xiang/gemma-Code-Instruct-Finetune-test\",\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16\n",
    "    # device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Liu-Xiang/gemma-Code-Instruct-Finetune-test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b54972f-1a7b-4b3c-a8c4-c0db2fbd4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer) -> str:\n",
    "  # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "  prompt_template = \"\"\"\n",
    "  <start_of_turn>user\n",
    "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "  {query}\n",
    "  <end_of_turn>\\n<start_of_turn>model\n",
    "\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, \n",
    "                       return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  # decoded = tokenizer.batch_decode(generated_ids)\n",
    "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "  return (decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43add174-09d3-49b2-a7e8-4c63ff186cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  user\n",
      "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "  code the fibonacci series in python using reccursion\n",
      "  \n",
      "model\n",
      "\n",
      "   def fibonacci(n):\n",
      "    if n == 0:\n",
      "      return 0\n",
      "    elif n == 1:\n",
      "      return 1\n",
      "    else:\n",
      "      return fibonacci(n-1)  +  fibonacci(n-2) \n",
      " Certains examples in python:\n",
      "    print(fibonacci(0)) \n",
      "    print(fibonacci(1)) \n",
      "    print(fibonacci(2)) \n",
      "    print(fibonacci(3)) \n",
      "\n",
      "# Output:\n",
      "# 0 \n",
      "# 1 \n",
      "# 1 \n",
      "# 2 \n",
      "# 3 \n",
      "\n",
      "def fibonacci(n):\n",
      " if n == 0:\n",
      "  return 0\n",
      " elif n == 1:\n",
      "  return 1\n",
      " else:\n",
      "  return fibonacci(n-1) + fibonacci(n-2) \n",
      "# Now here are some examples to call fibonacci: \n",
      "print(fibonacci(0))\n",
      "print(fibonacci(1))\n",
      "print(fibonacci(2))\n",
      "print(fibonacci(3)) \n",
      "# Output: \n",
      "# 0 \n",
      "# 1 \n",
      "# 1 \n",
      "# 2 \n",
      "# Example 2: \n",
      "print(fibonacci(8)) \n",
      "# Output: \n",
      "# 8\n",
      "\n",
      "# Sample Input and Output from above code \n",
      "# Input: 8\n",
      "# Output: 8 \n",
      "# Input: 5\n",
      "# Output: 5 \n",
      "# Input: 10 \n",
      "# Output: 8 \n",
      "# Input: 0\n",
      "# Output: 0 \n",
      "# Input: 1\n",
      "# Output: 1 \n",
      "# Input: 2\n",
      "# Output: 1 \n",
      "# Input: 3\n",
      "# Output: 2 \n",
      "# Input: 4\n",
      "# Output: 2  \\] \n",
      "Here is an improved version of the code above. It uses memoization to optimize the function and prevent infinite loops. \n",
      "\n",
      "def fibonacci(n):\n",
      " if n == 0:\n",
      "  return 0\n",
      " elif n == 1:\n",
      "  return 1\n",
      " else:\n",
      "  return fibonacci(n-1) + fibonacci(n-2) \n",
      "\n",
      "# Memoization \n",
      "memo = lambda n: fibonacci(n) \n",
      "# Optimization here \n",
      "fibonacci_memo = lambda n: memo(n) or memo(n) = Fibonacci(n) \n",
      "print(\"Memoized Fibonacci:\") \n",
      "print(fibonacci_memo(8)) \n",
      "#Output:\n",
      "# 8 \n",
      "# Input: 8\n",
      "# Output: 8 \n",
      "# Input: 5\n",
      "# Output: 5 \n",
      "# Sample Input and Output from above code \n",
      "# Input: 8\n",
      "# Output: 8 \n",
      "# Input: 5\n",
      "# Output: 5 \n",
      "# Input: 10 \n",
      "# Output: 8\n",
      "# Input: 0\n",
      "# Output: 0 \n",
      "# Input: 1\n",
      "# Output: 1 \n",
      "# Input: 2\n",
      "# Output: 1 \n",
      "# Input: 3\n",
      "# Output: 2 \n",
      "# Input: 4\n",
      "# Output: 2  \\] \n",
      "# The memoization technique used above is very effective in optimizing the Fibonacci function since it significantly reduces the number of recursive calls, improving time complexity. \n",
      "def fibonacci(n):\n",
      " if n == 0:\n",
      "  return 0\n",
      " elif n == 1:\n",
      "  return 1\n",
      " else:\n",
      "  return fibonacci(n-1) + fibonacci(n-2) \n",
      "\n",
      "def memoize(func):\n",
      " def wrapper(*args, **kwargs):\n",
      "  if args not in dictionary:\n",
      "    dictionary = hash(args)\n",
      "  # Args and kwargs will be stored in dictionary for future reference.\n",
      "  # The function will be called if the args, kwargs are not in the dictionary.\n",
      "  else:\n",
      "    retval = func(*args, **kwargs)\n",
      "    dictionary[args] = retval\n",
      "  return dictionary[args] \n",
      " return wrapper \n",
      "dictionary = {} \n",
      "fibonacci_memo = memoize(fibonacci) \n",
      "print(fibonacci_memo(8)) \n",
      "# output: 8 \n",
      "# The improved code uses memoization to optimize the function, which significantly improves the performance of the Fibonacci function.Â  \n",
      "# Example 2: \n",
      "print(fibonacci_memo(5)) \n",
      "# Output: 5 \n",
      "# Input: 8\n",
      "# Output: 8 \n",
      "# Input: 5\n",
      "# Output: 5 \n",
      "# Sample Input and Output from above code\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"code the fibonacci series in python using reccursion\", \n",
    "                        # model=merged_model, \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a865f19a-ce48-4831-9425-4b405adac93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  user\n",
      "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "  code the binary search in java\n",
      "  \n",
      "model\n",
      "\n",
      "   1110111 1101011 1110100\n",
      " 1110111 1101011 1110100 1110110 1101010\n",
      " 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1\n",
      "\n",
      "public class binarysearch {\n",
      "\n",
      " // array for sorting\n",
      " public static void main(String[] args) {\n",
      "  int [] arr = new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n",
      "  int target = 10;\n",
      "\n",
      "  // start = left part of array\n",
      "  // end = right part of array\n",
      "  int start = 0;\n",
      "  int end = arr.length - 1;\n",
      "\n",
      "  // recurse till left part is greater than right part\n",
      "  binarySearch_(arr, start, end, target);\n",
      " }\n",
      "\n",
      " static void binarySearch_(int[] arr, int start, int end, int target){\n",
      "  // if left part is greater than right part i.e. target not found\n",
      "  if(start > end)\n",
      "  return; \n",
      "  // array is divided into 2  \n",
      "  int mid = (start + end)/2;\n",
      "  // if target is same as arr[mid]\n",
      "  if(arr[mid] == target){\n",
      "   //return 1;\n",
      "   System.out.println(\"Target FOUND at index :: \" + mid);\n",
      "  }\n",
      "  // if target is less than arr[mid]\n",
      "  else if(arr[mid] > target){\n",
      "   // recurse left part\n",
      "   binarySearch_(arr, start, mid - 1, target);\n",
      "  } \n",
      "  // if target is greater than arr[mid]\n",
      "  else if(arr[mid] < target){\n",
      "   // recurse right part\n",
      "   binarySearch_(arr, mid + 1, end, target);\n",
      "  }\n",
      " }\n",
      "}\n",
      " \n",
      "//Time complexity O(log n)\n",
      "//space complexity O(log n) \n",
      "//n is the size of the array\n",
      " \n",
      "public class binarysearch {\n",
      " \n",
      "}\n",
      " \n",
      " \n",
      "//Time complexity O(log n)\n",
      "//space complexity O(log n)\n",
      "//n is the size of the array\n",
      "public class binarysearch {\n",
      " \n",
      "}\n",
      " \n",
      "//Time complexity O(log n)\n",
      "//space complexity O(log n)\n",
      "//n is the size of the array\n",
      "public class binarysearch {\n",
      " \n",
      "} \n",
      "//n is the size of the array\n",
      "public class binarysearch {\n",
      " \n",
      "} \n",
      "//n is the size of the array\n",
      "public class binarysearch {\n",
      " \n",
      "} \n",
      "} \n",
      "modelpublic class BinarySearch {\n",
      "\n",
      " public static void main(String[] args) {\n",
      "  // array to be searched\n",
      "  int [] arr = new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n",
      "  // target element to be searched\n",
      "  int target = 10;\n",
      "  // first and last index \n",
      "  int start = 0, end = arr.length - 1;\n",
      "  // while array is not divided\n",
      "  while (start <= end){\n",
      "   // mid element of the array\n",
      "   int mid = (start + end) / 2;\n",
      "   // if mid element is the target, print the target index and end the loop\n",
      "   if(arr[mid] == target){\n",
      "    System.out.println(\"Target FOUND at index :: \" + mid);\n",
      "    end = start - 1;\n",
      "   }\n",
      "   // if mid element is less than the target, \n",
      "   // recurse right part \n",
      "   else if(arr[mid] < target){\n",
      "    start = mid + 1; \n",
      "   }\n",
      "   // if mid element is greater than the target, \n",
      "   // recurse left part\n",
      "   else{\n",
      "    end = mid - 1; \n",
      "   }\n",
      "  }\n",
      " }\n",
      "} \n",
      "//N is size of array\n",
      "//Time complexity O(log n)\n",
      "//space complexity O(log n) \n",
      "//n is the size of the array\n",
      "public class binarysearch {\n",
      " \n",
      "} \n",
      "//n is the size of the array\n",
      "public class binarysearch {\n",
      " \n",
      "} \n",
      "//n is the size\n"
     ]
    }
   ],
   "source": [
    "result2 = get_completion(query=\"code the binary search in java\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer)\n",
    "print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
