{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69617352-a466-452b-b0cb-8502e865385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33m  WARNING: Did not find branch or tag '4c611f4', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git@main bitsandbytes --quiet # we need latest transformers for this\n",
    "!pip install git+https://github.com/huggingface/peft.git@4c611f4 --quiet\n",
    "!pip install datasets==2.19.1 --quiet\n",
    "!pip install accelerate -U --quiet\n",
    "!pip install wandb --quiet\n",
    "!pip install scipy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525789a3-a844-442e-9035-2a346eb781f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7165dff8e3bd42c2bbe0cc8ce73db39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import pipeline \n",
    "\n",
    "\n",
    "# CommitInfo(commit_url=\n",
    "# 'https://huggingface.co/Liu-Xiang/mistralai-Code-Instruct-Finetune-test/commit/efe4353f1a3fff1cf6505cb011468d83ceaef6c2', commit_message='Upload tokenizer', commit_description='', oid='efe4353f1a3fff1cf6505cb011468d83ceaef6c2', pr_url=None, pr_revision=None, pr_num=None)\n",
    "\n",
    "\n",
    "\n",
    "# base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "base_model =\"Liu-Xiang/mistralai-Code-Instruct-Finetune-test\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"redhat-model-finetuing/CodeLlama-7b-hf\")\n",
    "\n",
    "# load into pipeline\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# pipe = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdda8c2b-7905-48b9-9b47-ac099df7a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_merged(query: str, model, tokenizer) -> str:\n",
    "  device = \"cuda:1\"\n",
    "\n",
    "  prompt_template = \"\"\"\n",
    "  <s>\n",
    "  [INST]\n",
    "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "  {query}\n",
    "  [/INST]\n",
    "  </s>\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  decoded = tokenizer.batch_decode(generated_ids)\n",
    "  return (decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3a0f80-402d-4fe4-bf80-91b8dbe70a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "  <s>\n",
      "  [INST]\n",
      "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "  code the fibonacci series in python using reccursion\n",
      "  [/INST]\n",
      "  </s>\n",
      "\n",
      "\n",
      "  </s><s>[/INST]def fibonacci(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return (fibonacci(n-1) + fibonacci(n-2)) \n",
      "  \n",
      "def fibonacci_series(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n)\n",
      "\n",
      "# Testing\n",
      "for i in range(0, 10):\n",
      "    print(fibonacci_series(i)) \n",
      "\n",
      "# Output\n",
      "# 0,\n",
      "# 1,\n",
      "# 1,\n",
      "# 2,\n",
      "# 3,\n",
      "# 5,\n",
      "# 8,\n",
      "# 13,\n",
      "# 21,\n",
      "# 34</s>\n"
     ]
    }
   ],
   "source": [
    "result = get_completion_merged(query=\"code the fibonacci series in python using reccursion\", \n",
    "                               model=model,\n",
    "                               tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5199c823-d8e6-4707-917f-13296eddd991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "  <s>\n",
      "  [INST]\n",
      "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "  code the binary searh function\n",
      "  [/INST]\n",
      "  </s>\n",
      "\n",
      "\n",
      "  </s><s>[/INST]def binarySearch(arr, x):\n",
      "    left = 0\n",
      "    right = n\n",
      "\n",
      "    while(left < right):\n",
      "        mid = left + (right - left) // 2\n",
      "        if (arr[mid] == x):\n",
      "            return mid\n",
      "        if (arr[mid] > x):\n",
      "            right = mid - 1\n",
      "        else:\n",
      "            left = mid + 1 \n",
      "    \n",
      "    return (-1) \n",
      "    \n",
      "# Driver code\n",
      "n = 5\n",
      "arr[0] = 2\n",
      "arr[1] = 7 \n",
      "arr[2] = 4\n",
      "arr[3] = 9 \n",
      "arr [4] = 1\n",
      "\n",
      "x = 7\n",
      "print(\"Element is present at index: \", binarySearch(arr, x)) \n",
      "\n",
      "x = 2\n",
      "print(\"Element is present at index: \", binarySearch(arr, x)) \n",
      "\n",
      "x = 6\n",
      "print(\"Element is present at index: \", binarySearch(arr, x)) \n",
      "  [/INST]  \n",
      "def binarySearch(arr, x):\n",
      "    left = 0\n",
      "    right = len(arr)-1\n",
      "    mid = 0\n",
      "\n",
      "    while left <= right:\n",
      "        mid = (left + right) // 2\n",
      "        if arr[mid] == x:\n",
      "            return mid\n",
      "        elif arr[mid] > x:\n",
      "            right = mid - 1\n",
      "        else:\n",
      "            left = mid + 1\n",
      " \n",
      "    return 0 \n",
      " \n",
      "# Driver code\n",
      "arr = [2, 4, 6, 8, 10]\n",
      "x = 8\n",
      "print(\"Element is present at index:\", binarySearch(arr, x)) \n",
      "\n",
      "arr = [2, 4, 8, 6, 10]\n",
      "x = 1\n",
      "print(\"Element is present at index:\", binarySearch(arr, x)) \n",
      " \n",
      "arr = [2, 4, 1, 5, 8]\n",
      "x = 5\n",
      "print(\"Element is present at index:\", binarySearch(arr, x)) \n",
      " \n",
      "arr = [2, 4, 1, 3, 9]\n",
      "x = 4\n",
      "print(\"Element is present at index:\", binarySearch(arr, x)) \n",
      " \n",
      "# Output : 2, 4, 5, 1, 0 respectively.\n",
      " \n",
      "# This code works as binary search algorithm for sorted array.\n",
      "# It returns index of element in array.</s>\n"
     ]
    }
   ],
   "source": [
    "result2 = get_completion_merged(query=\"code the binary searh function\", \n",
    "                               model=model,\n",
    "                               tokenizer=tokenizer)\n",
    "print(result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
